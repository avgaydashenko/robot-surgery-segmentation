{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import cv2\n",
    "\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "from parse import search\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from utils import cuda\n",
    "\n",
    "from generate_masks import get_model\n",
    "from dataset import load_image\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.torch.functional import img_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transform(p=1):\n",
    "    return Compose([\n",
    "        Normalize(p=1)\n",
    "    ], p=p)\n",
    "\n",
    "def mask_overlay(image, mask, color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Helper function to visualize mask on the top of the car\n",
    "    \"\"\"\n",
    "    mask = np.dstack((mask, mask, mask)) * np.array(color)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)\n",
    "    img = image.copy()\n",
    "    ind = mask[:, :, 1] > 0    \n",
    "    img[ind] = weighted_sum[ind]    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img)\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'runs/debug/model.pt'\n",
    "model = get_model(model_path, model_type='AlbuNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/home/raznem/proj_kaggle_airbus/data/test_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15606 [00:00<?, ?it/s]/home/agaidash/anastasiia/lib/python3.6/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "100%|██████████| 15606/15606 [28:15<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "out_pred_rows = []\n",
    "\n",
    "for file_name in tqdm(list(data_path.glob('*'))):\n",
    "\n",
    "    c_img_name = search('test_v2/{}.jpg', str(file_name))[0]\n",
    "        \n",
    "    image = load_image(file_name)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_image = torch.unsqueeze(img_to_tensor(img_transform(p=1)(image=image)['image']).cuda(), dim=0)\n",
    "\n",
    "    mask = model(input_image)\n",
    "    mask_array = mask.data[0].cpu().numpy()[0]\n",
    "\n",
    "    cur_rles = multi_rle_encode(mask_array > 0)\n",
    "    \n",
    "    if len(cur_rles)>0:\n",
    "        for c_rle in cur_rles:\n",
    "            out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': c_rle}]\n",
    "    else:\n",
    "        out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>9763a5a22.jpg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>9a1e626ab.jpg</td>\n",
       "      <td>380483 6 381249 11 382014 15 382779 19 383545 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8839</th>\n",
       "      <td>d991a1df2.jpg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId                                      EncodedPixels\n",
       "13229  9763a5a22.jpg                                               None\n",
       "9447   9a1e626ab.jpg  380483 6 381249 11 382014 15 382779 19 383545 ...\n",
       "8839   d991a1df2.jpg                                               None"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# submission_df = pd.DataFrame(out_pred_rows)[['ImageId', 'EncodedPixels']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('/home/raznem/proj_kaggle_airbus/data/test_v2/efc2d1f3e.jpg')\n",
    "mask = rle_decode('514127 7 514893 12 515660 14 516427 15 517194 17 517962 17 518730 18 519498 18 520266 18 521034 19 521802 19 522570 19 523338 19 524105 20 524873 21 525640 22 526407 23 527175 23 527942 24 528709 25 529477 26 530245 26 531012 27 531780 27 532547 28 533315 28 534082 29 534850 29 535618 29 536386 28 537154 28 537922 28 538690 28 539458 28 540226 28 540994 28 541762 28 542531 27 543299 27 544067 27 544835 27 545603 27 546371 27 547139 27 547907 27 548675 27 549442 28 550210 28 550978 28 551746 28 552514 28 553281 29 554049 29 554817 29 555585 29 556353 29 557121 29 557889 29 558657 29 559425 28 560193 28 560961 28 561729 28 562496 29 563264 30 564032 30 564800 30 565568 30 566336 30 567104 30 567872 30 568640 29 569408 29 570176 29 570944 29 571712 29 572480 29 573248 28 574016 28 574784 28 575552 28 576320 28 577088 28 577856 28 578624 28 579391 29 580159 29 580927 29 581695 29 582463 29 583231 29 583998 30 584766 30 585534 30 586303 29 587071 29 587839 29 588607 29 589375 29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(mask_overlay(image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anastasiia",
   "language": "python",
   "name": "anastasiia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
